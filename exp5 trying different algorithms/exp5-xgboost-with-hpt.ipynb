{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>clean_comment</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>family mormon never tried explain still stare ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>buddhism much lot compatible christianity espe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>seriously say thing first get complex explain ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>learned want teach different focus goal not wr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>benefit may want read living buddha living chr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36241</th>\n",
       "      <td>37243</td>\n",
       "      <td>agree push make nation either pity pakistan in...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36242</th>\n",
       "      <td>37244</td>\n",
       "      <td>jesus</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36243</th>\n",
       "      <td>37245</td>\n",
       "      <td>kya bhai pure saal chutiya banaya modi aur jab...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36244</th>\n",
       "      <td>37246</td>\n",
       "      <td>downvote karna tha par upvote hogaya</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36245</th>\n",
       "      <td>37248</td>\n",
       "      <td>facebook working bjp cell</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36246 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                      clean_comment  category\n",
       "0               0  family mormon never tried explain still stare ...         1\n",
       "1               1  buddhism much lot compatible christianity espe...         1\n",
       "2               2  seriously say thing first get complex explain ...        -1\n",
       "3               3  learned want teach different focus goal not wr...         0\n",
       "4               4  benefit may want read living buddha living chr...         1\n",
       "...           ...                                                ...       ...\n",
       "36241       37243  agree push make nation either pity pakistan in...        -1\n",
       "36242       37244                                              jesus         0\n",
       "36243       37245  kya bhai pure saal chutiya banaya modi aur jab...         1\n",
       "36244       37246               downvote karna tha par upvote hogaya         0\n",
       "36245       37248                          facebook working bjp cell         0\n",
       "\n",
       "[36246 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"processed.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"rajatchauhan99/Youtube-Comment-Analysis-Chrome-Plugin\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"rajatchauhan99/Youtube-Comment-Analysis-Chrome-Plugin\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository rajatchauhan99/Youtube-Comment-Analysis-Chrome-Plugin initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository rajatchauhan99/Youtube-Comment-Analysis-Chrome-Plugin initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import dagshub\n",
    "dagshub.init(repo_owner='rajatchauhan99', repo_name='Youtube-Comment-Analysis-Chrome-Plugin', mlflow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/96c047f2f48c4d168382939725e408d8', creation_time=1729342817379, experiment_id='5', last_update_time=1729342817379, lifecycle_stage='active', name='Exp 5 - Trying Different ML Algos with HP Tuning', tags={}>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set or create an experiment\n",
    "import mlflow\n",
    "mlflow.set_experiment(\"Exp 5 - Trying Different ML Algos with HP Tuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-19 18:30:39,977] A new study created in memory with name: no-name-237ed102-2aa1-445c-90e9-634c2d47b497\n",
      "[I 2024-10-19 18:31:15,119] Trial 0 finished with value: 0.6582976962339633 and parameters: {'n_estimators': 169, 'learning_rate': 0.012435543967852432, 'max_depth': 7}. Best is trial 0 with value: 0.6582976962339633.\n",
      "[I 2024-10-19 18:31:47,267] Trial 1 finished with value: 0.6599530969788936 and parameters: {'n_estimators': 203, 'learning_rate': 0.01233988167940562, 'max_depth': 6}. Best is trial 1 with value: 0.6599530969788936.\n",
      "[I 2024-10-19 18:33:07,013] Trial 2 finished with value: 0.7846599530969789 and parameters: {'n_estimators': 269, 'learning_rate': 0.061278889002356694, 'max_depth': 9}. Best is trial 2 with value: 0.7846599530969789.\n",
      "[I 2024-10-19 18:34:40,785] Trial 3 finished with value: 0.5632501034625466 and parameters: {'n_estimators': 283, 'learning_rate': 0.0010712481173388547, 'max_depth': 6}. Best is trial 2 with value: 0.7846599530969789.\n",
      "[I 2024-10-19 18:36:27,310] Trial 4 finished with value: 0.5981514691681611 and parameters: {'n_estimators': 138, 'learning_rate': 0.0029421322017890053, 'max_depth': 8}. Best is trial 2 with value: 0.7846599530969789.\n",
      "[I 2024-10-19 18:37:51,631] Trial 5 finished with value: 0.7378948820526969 and parameters: {'n_estimators': 145, 'learning_rate': 0.04036174547826061, 'max_depth': 9}. Best is trial 2 with value: 0.7846599530969789.\n",
      "[I 2024-10-19 18:38:17,526] Trial 6 finished with value: 0.5193819837218927 and parameters: {'n_estimators': 105, 'learning_rate': 0.003411304349435142, 'max_depth': 3}. Best is trial 2 with value: 0.7846599530969789.\n",
      "[I 2024-10-19 18:39:04,815] Trial 7 finished with value: 0.5193819837218927 and parameters: {'n_estimators': 226, 'learning_rate': 0.0016076932706786658, 'max_depth': 3}. Best is trial 2 with value: 0.7846599530969789.\n",
      "[I 2024-10-19 18:43:08,344] Trial 8 finished with value: 0.5993930197268589 and parameters: {'n_estimators': 299, 'learning_rate': 0.00020750706889251927, 'max_depth': 10}. Best is trial 2 with value: 0.7846599530969789.\n",
      "[I 2024-10-19 18:44:48,916] Trial 9 finished with value: 0.7769347496206374 and parameters: {'n_estimators': 300, 'learning_rate': 0.06111275438438982, 'max_depth': 6}. Best is trial 2 with value: 0.7846599530969789.\n",
      "[I 2024-10-19 18:48:29,466] Trial 10 finished with value: 0.5996689198510139 and parameters: {'n_estimators': 238, 'learning_rate': 0.00017285908452381178, 'max_depth': 10}. Best is trial 2 with value: 0.7846599530969789.\n",
      "[I 2024-10-19 18:49:29,142] Trial 11 finished with value: 0.762449993102497 and parameters: {'n_estimators': 259, 'learning_rate': 0.06402045603681193, 'max_depth': 5}. Best is trial 2 with value: 0.7846599530969789.\n",
      "[I 2024-10-19 18:51:59,550] Trial 12 finished with value: 0.7548627396882328 and parameters: {'n_estimators': 297, 'learning_rate': 0.029183077967266914, 'max_depth': 8}. Best is trial 2 with value: 0.7846599530969789.\n",
      "[I 2024-10-19 18:52:19,283] Trial 13 finished with value: 0.6978893640502138 and parameters: {'n_estimators': 61, 'learning_rate': 0.09367433094972605, 'max_depth': 5}. Best is trial 2 with value: 0.7846599530969789.\n",
      "[I 2024-10-19 18:54:39,146] Trial 14 finished with value: 0.698717064422679 and parameters: {'n_estimators': 255, 'learning_rate': 0.013719616451571298, 'max_depth': 8}. Best is trial 2 with value: 0.7846599530969789.\n",
      "[I 2024-10-19 18:55:17,988] Trial 15 finished with value: 0.7129259208166644 and parameters: {'n_estimators': 209, 'learning_rate': 0.033642974354753996, 'max_depth': 5}. Best is trial 2 with value: 0.7846599530969789.\n",
      "[I 2024-10-19 18:56:26,608] Trial 16 finished with value: 0.7881087046489171 and parameters: {'n_estimators': 266, 'learning_rate': 0.0983738860018316, 'max_depth': 7}. Best is trial 16 with value: 0.7881087046489171.\n",
      "[I 2024-10-19 18:58:24,796] Trial 17 finished with value: 0.7108566698855014 and parameters: {'n_estimators': 186, 'learning_rate': 0.020252781543649692, 'max_depth': 9}. Best is trial 16 with value: 0.7881087046489171.\n",
      "[I 2024-10-19 19:00:13,196] Trial 18 finished with value: 0.6442267899020555 and parameters: {'n_estimators': 263, 'learning_rate': 0.006249148138386344, 'max_depth': 7}. Best is trial 16 with value: 0.7881087046489171.\n",
      "[I 2024-10-19 19:02:16,360] Trial 19 finished with value: 0.5781487101669196 and parameters: {'n_estimators': 222, 'learning_rate': 0.0004070996938725593, 'max_depth': 8}. Best is trial 16 with value: 0.7881087046489171.\n",
      "[I 2024-10-19 19:03:57,689] Trial 20 finished with value: 0.7923851565733204 and parameters: {'n_estimators': 266, 'learning_rate': 0.08799229696519144, 'max_depth': 9}. Best is trial 20 with value: 0.7923851565733204.\n",
      "[I 2024-10-19 19:05:40,625] Trial 21 finished with value: 0.7939026072561732 and parameters: {'n_estimators': 272, 'learning_rate': 0.09710052660794789, 'max_depth': 9}. Best is trial 21 with value: 0.7939026072561732.\n",
      "[I 2024-10-19 19:07:29,317] Trial 22 finished with value: 0.7941785073803284 and parameters: {'n_estimators': 245, 'learning_rate': 0.09544587036919938, 'max_depth': 10}. Best is trial 22 with value: 0.7941785073803284.\n",
      "[I 2024-10-19 19:09:47,612] Trial 23 finished with value: 0.7701751965788385 and parameters: {'n_estimators': 242, 'learning_rate': 0.040524404382763037, 'max_depth': 10}. Best is trial 22 with value: 0.7941785073803284.\n",
      "[I 2024-10-19 19:12:20,033] Trial 24 finished with value: 0.7441026348461857 and parameters: {'n_estimators': 280, 'learning_rate': 0.022425220543205743, 'max_depth': 9}. Best is trial 22 with value: 0.7941785073803284.\n",
      "[I 2024-10-19 19:15:38,090] Trial 25 finished with value: 0.6792661056697475 and parameters: {'n_estimators': 239, 'learning_rate': 0.007623737423977127, 'max_depth': 10}. Best is trial 22 with value: 0.7941785073803284.\n",
      "[I 2024-10-19 19:16:53,107] Trial 26 finished with value: 0.7850738032832115 and parameters: {'n_estimators': 185, 'learning_rate': 0.09933705356742832, 'max_depth': 9}. Best is trial 22 with value: 0.7941785073803284.\n",
      "[I 2024-10-19 19:18:51,012] Trial 27 finished with value: 0.7734859980686991 and parameters: {'n_estimators': 212, 'learning_rate': 0.05079265779100222, 'max_depth': 10}. Best is trial 22 with value: 0.7941785073803284.\n",
      "[I 2024-10-19 19:21:08,118] Trial 28 finished with value: 0.7372051317423093 and parameters: {'n_estimators': 281, 'learning_rate': 0.020177393492233638, 'max_depth': 9}. Best is trial 22 with value: 0.7941785073803284.\n",
      "[I 2024-10-19 19:22:20,560] Trial 29 finished with value: 0.7039591667816251 and parameters: {'n_estimators': 249, 'learning_rate': 0.015351788308917877, 'max_depth': 8}. Best is trial 22 with value: 0.7941785073803284.\n",
      "2024/10/19 19:24:28 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/10/19 19:24:51 INFO mlflow.tracking._tracking_service.client: üèÉ View run XGBoost_SMOTE_TFIDF_Trigrams at: https://dagshub.com/rajatchauhan99/Youtube-Comment-Analysis-Chrome-Plugin.mlflow/#/experiments/5/runs/fc7f4a60f5fa437087fff95b7bf04548.\n",
      "2024/10/19 19:24:51 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: https://dagshub.com/rajatchauhan99/Youtube-Comment-Analysis-Chrome-Plugin.mlflow/#/experiments/5.\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Remap the class labels from [-1, 0, 1] to [2, 0, 1]\n",
    "df['category'] = df['category'].map({-1: 2, 0: 0, 1: 1})\n",
    "\n",
    "# Step 2: Remove rows where the target labels (category) are NaN\n",
    "df = df.dropna(subset=['category'])\n",
    "\n",
    "ngram_range = (1, 3)  # Trigram setting\n",
    "max_features = 1000  # Set max_features to 1000 for TF-IDF\n",
    "\n",
    "# Step 4: Train-test split before vectorization and resampling\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['clean_comment'], df['category'], test_size=0.2, random_state=42, stratify=df['category'])\n",
    "\n",
    "# Step 2: Vectorization using TF-IDF, fit on training data only\n",
    "vectorizer = TfidfVectorizer(ngram_range=ngram_range, max_features=max_features)\n",
    "X_train_vec = vectorizer.fit_transform(X_train)  # Fit on training data\n",
    "X_test_vec = vectorizer.transform(X_test)  # Transform test data\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_vec, y_train = smote.fit_resample(X_train_vec, y_train)\n",
    "\n",
    "# Function to log results in MLflow\n",
    "def log_mlflow(model_name, model, X_train, X_test, y_train, y_test):\n",
    "    with mlflow.start_run():\n",
    "        # Log model type\n",
    "        mlflow.set_tag(\"mlflow.runName\", f\"{model_name}_SMOTE_TFIDF_Trigrams\")\n",
    "        mlflow.set_tag(\"experiment_type\", \"algorithm_comparison\")\n",
    "\n",
    "        # Log algorithm name as a parameter\n",
    "        mlflow.log_param(\"algo_name\", model_name)\n",
    "\n",
    "        # Train model\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Log accuracy\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "\n",
    "        # Log classification report\n",
    "        classification_rep = classification_report(y_test, y_pred, output_dict=True)\n",
    "        for label, metrics in classification_rep.items():\n",
    "            if isinstance(metrics, dict):\n",
    "                for metric, value in metrics.items():\n",
    "                    mlflow.log_metric(f\"{label}_{metric}\", value)\n",
    "\n",
    "        # Log the model\n",
    "        mlflow.sklearn.log_model(model, f\"{model_name}_model\")\n",
    "\n",
    "\n",
    "# Step 6: Optuna objective function for XGBoost\n",
    "def objective_xgboost(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 300)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-1, log=True)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 10)\n",
    "\n",
    "    model = XGBClassifier(n_estimators=n_estimators, learning_rate=learning_rate, max_depth=max_depth, random_state=42)\n",
    "    return accuracy_score(y_test, model.fit(X_train_vec, y_train).predict(X_test_vec))\n",
    "\n",
    "\n",
    "# Step 7: Run Optuna for XGBoost, log the best model only\n",
    "def run_optuna_experiment():\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective_xgboost, n_trials=30)\n",
    "\n",
    "    # Get the best parameters and log only the best model\n",
    "    best_params = study.best_params\n",
    "    best_model = XGBClassifier(n_estimators=best_params['n_estimators'], learning_rate=best_params['learning_rate'], max_depth=best_params['max_depth'], random_state=42)\n",
    "\n",
    "    # Log the best model with MLflow, passing the algo_name as \"xgboost\"\n",
    "    log_mlflow(\"XGBoost\", best_model, X_train_vec, X_test_vec, y_train, y_test)\n",
    "\n",
    "# Run the experiment for XGBoost\n",
    "run_optuna_experiment()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
