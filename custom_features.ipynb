{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "-iYtOsb0RabA"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "FmaP_pJhRn8p"
   },
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "dataset = pd.read_csv('processed.csv')\n",
    "\n",
    "# Drop rows with NaN values in 'clean_comment'\n",
    "cleaned_dataset = dataset.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "zfgNm_b5Rt2o"
   },
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X_cleaned = cleaned_dataset['clean_comment']\n",
    "y_cleaned = cleaned_dataset['category']\n",
    "\n",
    "# Split the cleaned data into train and test sets (80-20 split)\n",
    "X_train_cleaned, X_test_cleaned, y_train_cleaned, y_test_cleaned = train_test_split(X_cleaned, y_cleaned, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     --- ------------------------------------ 1.0/12.8 MB 5.6 MB/s eta 0:00:03\n",
      "     ------- -------------------------------- 2.4/12.8 MB 5.8 MB/s eta 0:00:02\n",
      "     --------- ------------------------------ 3.1/12.8 MB 5.3 MB/s eta 0:00:02\n",
      "     --------- ------------------------------ 3.1/12.8 MB 5.3 MB/s eta 0:00:02\n",
      "     ---------------- ----------------------- 5.2/12.8 MB 5.1 MB/s eta 0:00:02\n",
      "     ---------------- ----------------------- 5.2/12.8 MB 5.1 MB/s eta 0:00:02\n",
      "     ---------------------- ----------------- 7.3/12.8 MB 5.1 MB/s eta 0:00:02\n",
      "     --------------------------- ------------ 8.9/12.8 MB 5.4 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 10.7/12.8 MB 5.8 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 12.3/12.8 MB 6.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 12.8/12.8 MB 5.8 MB/s eta 0:00:00\n",
      "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "AflOAY7qR3R8"
   },
   "outputs": [],
   "source": [
    "# Load spacy language model for POS tagging\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "n58anZRgR840"
   },
   "outputs": [],
   "source": [
    "# Function to extract custom features\n",
    "def extract_custom_features(text):\n",
    "    doc = nlp(text)\n",
    "    word_list = [token.text for token in doc]\n",
    "\n",
    "    # 1. Comment Length (number of characters)\n",
    "    comment_length = len(text)\n",
    "\n",
    "    # 2. Word Count\n",
    "    word_count = len(word_list)\n",
    "\n",
    "    # 3. Average Word Length\n",
    "    avg_word_length = sum(len(word) for word in word_list) / word_count if word_count > 0 else 0\n",
    "\n",
    "    # 4. Unique Word Count\n",
    "    unique_word_count = len(set(word_list))\n",
    "\n",
    "    # 5. Lexical Diversity\n",
    "    lexical_diversity = unique_word_count / word_count if word_count > 0 else 0\n",
    "\n",
    "    # 6. Count of POS Tags\n",
    "    pos_count = len([token.pos_ for token in doc])\n",
    "\n",
    "    # 7. Proportion of POS Tags\n",
    "    pos_tags = [token.pos_ for token in doc]\n",
    "    pos_proportion = {tag: pos_tags.count(tag) / word_count for tag in set(pos_tags)} if word_count > 0 else {}\n",
    "\n",
    "    return {\n",
    "        'comment_length': comment_length,\n",
    "        'word_count': word_count,\n",
    "        'avg_word_length': avg_word_length,\n",
    "        'unique_word_count': unique_word_count,\n",
    "        'lexical_diversity': lexical_diversity,\n",
    "        'pos_count': pos_count,\n",
    "        **pos_proportion  # Flattening the POS proportions\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HCsNR_kiSB3N"
   },
   "outputs": [],
   "source": [
    "# Apply the custom feature extraction\n",
    "train_custom_features = pd.DataFrame([extract_custom_features(text) for text in X_train_cleaned])\n",
    "test_custom_features = pd.DataFrame([extract_custom_features(text) for text in X_test_cleaned])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "id": "nEAHs7IBSFpo",
    "outputId": "061dd54c-8d8b-4917-b06b-4be5ec85aab8"
   },
   "outputs": [],
   "source": [
    "train_custom_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "25dXeJo1UiSo"
   },
   "outputs": [],
   "source": [
    "# Replace NaN values in POS tag proportions with 0\n",
    "train_custom_features.fillna(0, inplace=True)\n",
    "test_custom_features.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 805
    },
    "id": "ieXhReRMUkrR",
    "outputId": "fb0c67bf-a2dc-4f04-dc0e-06b1611247ab"
   },
   "outputs": [],
   "source": [
    "test_custom_features.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wslm78Q-Sgk7"
   },
   "outputs": [],
   "source": [
    "# Apply TfidfVectorizer with trigram setting and max_features=1000\n",
    "tfidf = TfidfVectorizer(ngram_range=(1, 3), max_features=1000)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train_cleaned)\n",
    "X_test_tfidf = tfidf.transform(X_test_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R2nbMoNUSkXW"
   },
   "outputs": [],
   "source": [
    "# Convert TF-IDF to DataFrame\n",
    "X_train_tfidf_df = pd.DataFrame(X_train_tfidf.toarray(), columns=tfidf.get_feature_names_out())\n",
    "X_test_tfidf_df = pd.DataFrame(X_test_tfidf.toarray(), columns=tfidf.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CXEAS2pBSnVJ"
   },
   "outputs": [],
   "source": [
    "# Combine TF-IDF and custom features\n",
    "X_train_combined = pd.concat([X_train_tfidf_df.reset_index(drop=True), train_custom_features.reset_index(drop=True)], axis=1)\n",
    "X_test_combined = pd.concat([X_test_tfidf_df.reset_index(drop=True), test_custom_features.reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 461
    },
    "id": "p1W06TanSqOQ",
    "outputId": "fdc24c68-69af-410b-8a02-ceeb64ff0b46"
   },
   "outputs": [],
   "source": [
    "X_train_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hP2uR1D9U5c7",
    "outputId": "a2727592-98b6-430f-e4c2-8b8121244319"
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RE02imaqVREd"
   },
   "outputs": [],
   "source": [
    "model = lgb.LGBMClassifier(\n",
    "\n",
    "    objective='multiclass',\n",
    "    num_class=3,\n",
    "    metric=\"multi_logloss\",\n",
    "    is_unbalance= True,\n",
    "    class_weight= \"balanced\",\n",
    "    reg_alpha= 0.1,  # L1 regularization\n",
    "    reg_lambda= 0.1,  # L2 regularization\n",
    "    learning_rate= 0.08081298097796712,\n",
    "    n_estimators= 367,\n",
    "    max_depth= 20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "NZd6wa2yVf-y",
    "outputId": "d086f9a5-1ac5-46e8-8952-036306aae7c6"
   },
   "outputs": [],
   "source": [
    "# Fit the model on the resampled training data\n",
    "model.fit(X_train_combined, y_train_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1D6Xxbw9VtRj",
    "outputId": "fe888257-5d2e-4791-cade-ae9d4f4fff38"
   },
   "outputs": [],
   "source": [
    "# Predict on the test set\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = model.predict(X_test_combined)\n",
    "accuracy = accuracy_score(y_test_cleaned, y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B0RvB5poWRtL",
    "outputId": "ccaf8faa-e728-43bd-d729-40e27ac4da64"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "# Generate classification report\n",
    "report = classification_report(y_test_cleaned, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Z9vQ8NFWqX2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
